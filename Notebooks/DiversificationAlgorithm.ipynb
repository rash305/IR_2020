{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yafqGN5QONzE"
   },
   "source": [
    "# Diversification Algorithm\n",
    "\n",
    "This notebook can take in a BM25 ranking and rerank the results for each query with our diversification algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFjpKSs_vIda"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsovxoBh3gZ0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Cc2S8S0Lff7"
   },
   "source": [
    "# Mount google drive to get data\n",
    "(just for Marit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 786,
     "status": "ok",
     "timestamp": 1608234496740,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "JUOPUt0sLc1X",
    "outputId": "50797990-14fc-4376-ef59-a0dbbd1b0d04"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2140f9879d71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gdrive/My Drive/Information Retrieval/Information Retrieval Project/Notebooks'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive');\n",
    "os.chdir('gdrive/My Drive/Information Retrieval/Information Retrieval Project/Notebooks')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU1gu_RfvIdm"
   },
   "source": [
    "## Functions for the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptcc1cbR7yP0"
   },
   "outputs": [],
   "source": [
    "def computeFairnessConstraints(G, k=10, SPC=True):\n",
    "    \"\"\"\n",
    "    Compute the fairness constraints given the disjoint diversity groups\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G:            Set of disjoint diversity groups\n",
    "    k:            Number of documents in the final ranking\n",
    "    SPC:          Specifies how to compute the fairness contraints\n",
    "                  True  = SPC, statistical parity constraint\n",
    "                  False = DIC, disparate impact constraint\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    F:            Fairness constraints\n",
    "    \"\"\"\n",
    "    g = len(G)\n",
    "    F = np.zeros(g)\n",
    "    if SPC:           # Statistical parity constraint\n",
    "        fi = k/g\n",
    "        F[:] = fi\n",
    "    else:             # Disparate impact constraint\n",
    "        n = sum([len(G[Gi]) for Gi in G])\n",
    "        for i in range(g):\n",
    "            gi = len(G[i])\n",
    "            fi = k*gi/n\n",
    "            F[i] = fi\n",
    "\n",
    "    return F\n",
    "\n",
    "def rerank(G, F, RsD, query_scores, document_id_linked_to_group, k=100, e=0.1):\n",
    "    \"\"\"\n",
    "    Rerank the document in RsD, according to the reranking algorithm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G:            Set of disjoint diversity groups\n",
    "    F:            Fairness constraints\n",
    "    RsD:          Original ranking\n",
    "    query_scores: BM25 scores of original ranking\n",
    "    k:            Number of documents in the final ranking\n",
    "    e:            Epsilon, probability to 'explore'\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    reranking:    New top k ranking\n",
    "    scores:       New top k scores\n",
    "    \"\"\"\n",
    "    # Select top result of original ranking and add to Dk\n",
    "    doc   = RsD[0]\n",
    "    score = query_scores[0]\n",
    "    Dk    = { 0: doc }\n",
    "    Sk    = { 0: score }\n",
    "    groupIndexOfAddedDoc = document_id_linked_to_group[doc]\n",
    "\n",
    "    # Update currentGroupDistributionInDk\n",
    "    # currentGroupDistributionInDk keeps track of how many docs of each group\n",
    "    # are in the Dk\n",
    "    currentGroupDistributionInDk = np.zeros(len(G))\n",
    "    currentGroupDistributionInDk[groupIndexOfAddedDoc] += 1\n",
    "\n",
    "    # Loop to add k-1 documents to Dk according to the reranking algorithm\n",
    "    i = 1\n",
    "    default_cluster = len(G)-1\n",
    "    while i < k+1:\n",
    "        p = random.random()\n",
    "        if p < e:\n",
    "            # Probability is smaller dan epsilon, thus randomly explore\n",
    "            # j is a randomly selected group number\n",
    "            j = random.randrange(len(G))    \n",
    "        else:\n",
    "            # Probability is bigger dan epsilon, thus exploit known information\n",
    "            # Find group number which is underrepresented according to the fairness contraints\n",
    "            # j is the underrepresented group number\n",
    "            j = next(\n",
    "                    (j for j, n in enumerate(currentGroupDistributionInDk) if n < F[j]*(i/k)),\n",
    "                    default_cluster)\n",
    "        # Get documents in selected group\n",
    "        C = G[j]\n",
    "        # Update currentGroupDistributionInDk\n",
    "        currentGroupDistributionInDk[j] += 1\n",
    "\n",
    "        # Select top result of C (according to the original ranking) and add to Dk \n",
    "        rank, doc = getTopDoc(RsD, C)\n",
    "        if rank is not None and doc is not None:\n",
    "            Dk[rank] = doc\n",
    "            Sk[rank] = query_scores[rank]\n",
    "            i = i+1\n",
    "        else:\n",
    "            default_cluster = default_cluster-1   \n",
    "            if default_cluster is -1:\n",
    "                default_cluster = len(G) - 1\n",
    "\n",
    "    # Sort Dk and Sk according to the orginal ranking\n",
    "    reranking = sorted(Dk.items())\n",
    "    scores    = sorted(Sk.items())\n",
    "    return [document[1] for document in reranking], [score[1] for score in scores]\n",
    "\n",
    "def getTopDoc(RsD, D):\n",
    "    \"\"\"\n",
    "    Get document from set D with the higest rank according to the original algorithm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    D:          Group of documents\n",
    "    RsD:        All documents with original ranking\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    rank:       Rank of the document\n",
    "    doc:        Document ID\n",
    "    \"\"\"\n",
    "    # Loop over all documents\n",
    "    for rank_index, document in enumerate(RsD):\n",
    "        # If document is present in the group, return the document with rank\n",
    "        if document in D:\n",
    "            D.remove(document)\n",
    "            return rank_index, document\n",
    "    # No document present in the group\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xunhb_03vIds"
   },
   "source": [
    "## Load necessary datasets in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rX7iibh8vIdt"
   },
   "outputs": [],
   "source": [
    "# Load in BM25 ranking\n",
    "document_ranking = pd.read_csv(\"../Data/results/ranking.bm25.train.csv\", sep=',', index_col=0, header=0 )\n",
    "document_ranking.ranking = document_ranking.ranking.apply(eval)\n",
    "document_ranking.scores  = document_ranking.scores.apply(eval)\n",
    "\n",
    "# Load in LDA scores\n",
    "document_lda = pd.read_csv(\"../Data/clean/document_lda_groups.train.csv\", sep=',', index_col=0, header=0 ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KyCxh19vIdt"
   },
   "outputs": [],
   "source": [
    "# Preview of BM25 ranking\n",
    "document_ranking.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-0NPuppvIdt"
   },
   "source": [
    "### Create document group dictionarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHASjPzxvIdu"
   },
   "outputs": [],
   "source": [
    "def createDocumentIdLinkedToGroup(document_lda):\n",
    "    document_id_linked_to_group =  {}\n",
    "\n",
    "    # for each medical document\n",
    "    for index, document_id in enumerate (document_lda.index.values):\n",
    "        # Lookup the LDA group\n",
    "        group = np.argmax(document_lda.iloc[index])\n",
    "        # Append document ID to the dictionary under the Group key \n",
    "        document_id_linked_to_group[document_id] = group\n",
    "    return document_id_linked_to_group\n",
    "\n",
    "document_id_linked_to_group = createDocumentIdLinkedToGroup(document_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYGAIJVavIdu"
   },
   "outputs": [],
   "source": [
    "def createGroups(lda_scores, query_document_ranking):\n",
    "    document_groups =  { \n",
    "        0: [],\n",
    "        1: [],\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: [],\n",
    "        6: [],\n",
    "        7: [],\n",
    "        8: [],\n",
    "        9: [],\n",
    "        10: [],\n",
    "        11: [],\n",
    "        12: [],\n",
    "        13: []\n",
    "    }\n",
    "\n",
    "    # for each medical document\n",
    "    for document_id in query_document_ranking:\n",
    "        # Lookup the LDA group\n",
    "        group = np.argmax(lda_scores.loc[document_id])\n",
    "        # Append document ID to the dictionary under the Group key \n",
    "        document_groups[group].append(document_id)\n",
    "\n",
    "    return document_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_hupv5avIdv"
   },
   "source": [
    "## Rerank ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0Z7GwjivIdv"
   },
   "outputs": [],
   "source": [
    "# K Number of documents in the final ranking\n",
    "# e Epsilon, probability to 'explore'\n",
    "def process_query(query_id, query_ranking, query_scores, lda_scores, document_id_linked_to_group, SPC = True, k = 100, e = 0.5 ):\n",
    "    # Initialize/compute original ranking\n",
    "    RsD = query_ranking\n",
    "\n",
    "    # Initialize groups\n",
    "    # Make set of groups\n",
    "    G = createGroups(lda_scores, query_ranking)\n",
    "    # Compute fairness constraints\n",
    "    F = computeFairnessConstraints(G, k, SPC)\n",
    "\n",
    "    # Rerank the original ranking with the reranking algorithm\n",
    "    newRanking, newScores = rerank(G, F, RsD, query_scores, document_id_linked_to_group, k, e)\n",
    "\n",
    "    return newRanking, newScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-Rlg6PwjdfB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WaUPsb2d8mW"
   },
   "source": [
    "### Rerank with both fairness constraints\n",
    "(Both constraints seperate for only train data are at the bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydLL3riRdoFf",
    "outputId": "42983a16-9320-44e7-af0b-10e741e60b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t    Reranking train data\n"
     ]
    }
   ],
   "source": [
    "# Specify data types\n",
    "data_types = ['train']#['', 'dev', 'test']\n",
    "# Specify the top n's\n",
    "top_n = [10, 100]\n",
    "# Specify the fairness constraint types\n",
    "types   = ['spc', 'dic']\n",
    "# Specify the epsilon values\n",
    "epsilon = [0, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 1]\n",
    "\n",
    "# Loop over data types\n",
    "for dt in data_types:\n",
    "    print(f\"\\n\\t    Reranking {dt} data\")\n",
    "\n",
    "    # Reading BM25 ranking in\n",
    "    BM25_ranking = pd.read_csv(f\"../Data/results/ranking.bm25.csv\", sep=',', index_col=0, header=0 )\n",
    "    BM25_ranking.ranking = BM25_ranking.ranking.apply(eval)\n",
    "    BM25_ranking.scores  = BM25_ranking.scores.apply(eval)\n",
    "\n",
    "    # Reading LDA scores\n",
    "    document_lda = pd.read_csv(f\"../Data/clean/document_lda_groups.csv\", sep=',', index_col=0, header=0 ).fillna(0)\n",
    "    document_id_linked_to_group = createDocumentIdLinkedToGroup(document_lda)\n",
    "\n",
    "    # Loop over the top n's\n",
    "    for top in top_n:\n",
    "        print(f\"\\tReranking a new top {top}\")\n",
    "        # Loop over fairness constraint types\n",
    "        for t in types:\n",
    "            print(f\"    Reranking with the {t.upper()} fairness contraint\")\n",
    "            # Loop over epsilon values\n",
    "            for e in epsilon:\n",
    "                print(f\"Reranking with e={e}\")\n",
    "\n",
    "                # Initialize dataframe for reranking\n",
    "                reranking_ranking_df = pd.DataFrame(columns = ['query', 'ranking', 'scores'])\n",
    "\n",
    "                # Loop over all queries\n",
    "                for query_id in tqdm(BM25_ranking.index.values):\n",
    "                    # Create reranking for query\n",
    "                    reranking, scores    = process_query(query_id, BM25_ranking.ranking.loc[query_id], BM25_ranking.scores.loc[query_id], document_lda, document_id_linked_to_group, e=e, k=top)\n",
    "                    # Store reranking with scores\n",
    "                    reranking_ranking_df = reranking_ranking_df.append({'query': query_id, 'ranking': reranking, 'scores': scores}, ignore_index=True)\n",
    "                \n",
    "                # Save reranking to file\n",
    "                reranking_ranking_df = reranking_ranking_df.set_index('query')\n",
    "                reranking_ranking_df.to_csv(f'../Data/results/{t}/reranking.top{top}.{t}.e{e}.train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywkkkwAYd6dV"
   },
   "source": [
    "### Rerank with SPC fairness constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXRq1t1zvIdv"
   },
   "outputs": [],
   "source": [
    "Knal eruit met een error\n",
    "epsilon = [0, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 1]\n",
    "for e in epsilon:\n",
    "    reranking_ranking_df = pd.DataFrame(columns = ['query', 'ranking', 'scores'])\n",
    "\n",
    "    for query_id in tqdm(document_ranking.index.values):\n",
    "        reranking, scores    = process_query(query_id, document_ranking.ranking.loc[query_id], document_ranking.scores.loc[query_id], document_lda, document_id_linked_to_group, e=e)\n",
    "        reranking_ranking_df = reranking_ranking_df.append({'query': query_id, 'ranking': reranking, 'scores': scores}, ignore_index=True)\n",
    "    \n",
    "    reranking_ranking_df = reranking_ranking_df.set_index('query')\n",
    "    reranking_ranking_df.to_csv(f'../Data/results/spc/reranking.spc.e{e}.train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvuMuSwwh3dR"
   },
   "source": [
    "### Rerank with DIC fairness constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pj4-zXV9vIdw",
    "outputId": "0f942e01-3dfd-4a6f-8404-e0cc4d4c90bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [10:42<00:00,  5.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [10:42<00:00,  5.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [10:44<00:00,  5.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [10:41<00:00,  5.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [10:41<00:00,  5.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [10:40<00:00,  5.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [10:38<00:00,  5.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [10:38<00:00,  5.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [10:37<00:00,  5.36it/s]\n"
     ]
    }
   ],
   "source": [
    "Knal eruit met een error\n",
    "epsilon = [0, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 1]\n",
    "for e in epsilon:\n",
    "    reranking_ranking_df = pd.DataFrame(columns = ['query', 'ranking', 'scores'])\n",
    "\n",
    "    for query_id in tqdm(document_ranking.index.values):\n",
    "        reranking, scores    = process_query(query_id, document_ranking.ranking.loc[query_id], document_ranking.scores.loc[query_id], document_lda, document_id_linked_to_group, SPC=False, e=e)\n",
    "        reranking_ranking_df = reranking_ranking_df.append({'query': query_id, 'ranking': reranking, 'scores': scores}, ignore_index=True)\n",
    "        \n",
    "    reranking_ranking_df = reranking_ranking_df.set_index('query')\n",
    "    reranking_ranking_df.to_csv(f'../Data/results/dic/reranking.dic.e{e}.train.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DiversificationAlgorithm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
