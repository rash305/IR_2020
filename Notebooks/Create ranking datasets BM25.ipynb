{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghcPy04i-Ik2"
   },
   "source": [
    "# Mount google drive to get data\n",
    "(just for Marit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34621,
     "status": "ok",
     "timestamp": 1608213170713,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "21HMNeAa-F3m",
    "outputId": "796bcc8d-d4c4-432e-d5a0-c1bdeef5db1f"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive');\n",
    "# os.chdir('gdrive/My Drive/Information Retrieval/Information Retrieval Project/Notebooks')\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4zgD71fzc1K"
   },
   "source": [
    "## Install not common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8CFcLmp6zc1P",
    "outputId": "70f486b5-bc6e-42c0-b9a3-f47793f08568"
   },
   "outputs": [],
   "source": [
    "# !pip install janome\n",
    "# !pip install gensim\n",
    "# !pip install nltk\n",
    "# !pip install tqdm\n",
    "# !pip3 install stemming\n",
    "# !pip install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUfDQ1wIzc1R"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1608213664929,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "DAmyyr7Dzc1R",
    "outputId": "8618c7df-fc83-499e-f59e-12b152842e80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sjoerd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "# import re\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from rank_bm25 import BM25Okapi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ8By6e6zc1S"
   },
   "source": [
    "### Preprocess text methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 1680,
     "status": "ok",
     "timestamp": 1608213289039,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "QHRZyJEizc1S"
   },
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "stop_words_path = '..\\\\Data\\\\nfcorpus\\\\raw\\\\stopwords.large'\n",
    "stop_words_path = '../Data/nfcorpus/raw/stopwords.large'\n",
    "# create list of stop words in stopword document\n",
    "with open(stop_words_path, encoding='utf-8') as f:\n",
    "    for l in f:\n",
    "        if l[0] in ('\\n', '#'):\n",
    "            continue\n",
    "        stopwords.append(l.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1608213334469,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "_4V5aYzozc1S"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Write a function to perform the pre processing steps on the entire dataset\n",
    "'''\n",
    "def lemmatize_stemming(text):\n",
    "    return SnowballStemmer(\"english\").stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in stopwords and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2389,
     "status": "ok",
     "timestamp": 1608213397087,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "EtKHSa9Bzc1S",
    "outputId": "a09a22ce-8199-4541-c98f-961cd5fcaf80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test string walking the beaches study\n",
      "['test', 'string', 'walk', 'beach', 'studi']\n"
     ]
    }
   ],
   "source": [
    "# test preprocess actions\n",
    "test_sentence = \"test string walking the beaches study\"\n",
    "print(test_sentence)\n",
    "print(preprocess(test_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13294,
     "status": "ok",
     "timestamp": 1608213451181,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "8kjELxYIzc1S",
    "outputId": "e3d262b6-40cd-4244-97e5-82866482c919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of the raw dataset are ['URL' 'TITLE' 'MAINTEXT' 'COMMENTS' 'TOPICS_TAGS' 'DESCRIPTION'\n",
      " 'DOCTORS_NOTE' 'ARTICLE_LINKS' 'QUESTION_LINKS' 'TOPIC_LINKS'\n",
      " 'VIDEO_LINKS' 'MEDARTICLE_LINKS']\n"
     ]
    }
   ],
   "source": [
    "# load the raw query documents\n",
    "raw_dataset = pd.read_csv(\"../Data/nfcorpus/raw/nfdump.txt\", sep='\\t', index_col=False, header=None )\n",
    "clean_queries = raw_dataset#[[0, 5]]\n",
    "# Column names from the readme\n",
    "column_names = {\n",
    "    0: \"ID\",\n",
    "    1 : \"URL\",\n",
    "    2 : \"TITLE\",\n",
    "    3 : \"MAINTEXT\",\n",
    "    4 : \"COMMENTS\",\n",
    "    5 : \"TOPICS_TAGS\",\n",
    "    6 : \"DESCRIPTION\",\n",
    "    7 : \"DOCTORS_NOTE\",\n",
    "    8 : \"ARTICLE_LINKS\",\n",
    "    9 : \"QUESTION_LINKS\", \n",
    "    10: \"TOPIC_LINKS\", \n",
    "    11: \"VIDEO_LINKS\",\n",
    "    12: \"MEDARTICLE_LINKS\"\n",
    "}\n",
    "## Add column names to columns that need to be referenced later \n",
    "clean_queries = clean_queries.rename(columns=column_names)\n",
    "# Delete all advertisements\n",
    "Ad_indices = clean_queries[(clean_queries.TOPICS_TAGS == 'DVD') | (clean_queries.TOPICS_TAGS == 'jobs')].index\n",
    "clean_queries = clean_queries.drop(Ad_indices)\n",
    "\n",
    "# Set indices to document identifiers\n",
    "clean_queries = clean_queries.set_index('ID')\n",
    "\n",
    "# Reformat topic string to topic array\n",
    "clean_queries['TOPICS_TAGS'] = clean_queries.TOPICS_TAGS.apply(lambda x: x.split(','))\n",
    "## Stopword removal, Lemmatize and stemming of the title and maintext\n",
    "clean_queries.TITLE = clean_queries.TITLE.apply(preprocess)\n",
    "clean_queries.MAINTEXT = clean_queries.MAINTEXT.apply(preprocess)\n",
    "preprocess\n",
    "print(f\"The columns of the raw dataset are {clean_queries.columns.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1608213465046,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "69J0hhPkzc1T",
    "outputId": "53d6f665-990e-4daa-8329-8e502e49b0d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>MAINTEXT</th>\n",
       "      <th>COMMENTS</th>\n",
       "      <th>TOPICS_TAGS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>DOCTORS_NOTE</th>\n",
       "      <th>ARTICLE_LINKS</th>\n",
       "      <th>QUESTION_LINKS</th>\n",
       "      <th>TOPIC_LINKS</th>\n",
       "      <th>VIDEO_LINKS</th>\n",
       "      <th>MEDARTICLE_LINKS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PLAIN-1</th>\n",
       "      <td>http://nutritionfacts.org/2015/07/21/why-deep-...</td>\n",
       "      <td>[deep, fri, food, cancer]</td>\n",
       "      <td>[latest, studi, dietari, pattern, breast, canc...</td>\n",
       "      <td>Even before the oil gets in the fryer, it’s be...</td>\n",
       "      <td>[acrylamide, beans, breast cancer, cabbage, ca...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>http://nutritionfacts.org/topics/organic-foods...</td>\n",
       "      <td>http://nutritionfacts.org/video/meat-fumes-die...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/23092936,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLAIN-2</th>\n",
       "      <td>http://nutritionfacts.org/2015/07/16/do-choles...</td>\n",
       "      <td>[cholesterol, statin, drug, breast, cancer]</td>\n",
       "      <td>[breast, cancer, cholesterol, potenti, mechan,...</td>\n",
       "      <td>Off topic, but what does the science say about...</td>\n",
       "      <td>[breast cancer, cancer, cancer survival, cardi...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>http://nutritionfacts.org/topics/organic-foods...</td>\n",
       "      <td>http://nutritionfacts.org/video/statin-cholest...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/16565487,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLAIN-3</th>\n",
       "      <td>http://nutritionfacts.org/2015/07/14/breast-ca...</td>\n",
       "      <td>[breast, cancer, cell, fee, cholesterol]</td>\n",
       "      <td>[american, women, diagnos, breast, cancer, lif...</td>\n",
       "      <td>When I eat fresh stalks of celery my mouth goe...</td>\n",
       "      <td>[body fat, breast cancer, breast cancer surviv...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>http://nutritionfacts.org/topics/organic-foods...</td>\n",
       "      <td>http://nutritionfacts.org/video/flaxseeds-brea...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/3081176,htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLAIN-4</th>\n",
       "      <td>http://nutritionfacts.org/2015/07/09/using-die...</td>\n",
       "      <td>[diet, treat, asthma, eczema]</td>\n",
       "      <td>[previous, discuss, power, fruit, veget, preve...</td>\n",
       "      <td>I am confused about coconut fat. Is it the pro...</td>\n",
       "      <td>[asthma, blood pressure, caloric restriction, ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>http://nutritionfacts.org/topics/organic-foods...</td>\n",
       "      <td>http://nutritionfacts.org/video/uprooting-the-...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/11840688,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLAIN-5</th>\n",
       "      <td>http://nutritionfacts.org/2015/07/07/treating-...</td>\n",
       "      <td>[treat, asthma, plant, pill]</td>\n",
       "      <td>[video, treat, asthma, fruit, veget, highlight...</td>\n",
       "      <td>Maybe the asthma trick is in what not to eat. ...</td>\n",
       "      <td>[allergies, antioxidants, apples, asthma, bean...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>http://nutritionfacts.org/topics/organic-foods...</td>\n",
       "      <td>http://nutritionfacts.org/video/alkylphenol-en...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/21623967,ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       URL  \\\n",
       "ID                                                           \n",
       "PLAIN-1  http://nutritionfacts.org/2015/07/21/why-deep-...   \n",
       "PLAIN-2  http://nutritionfacts.org/2015/07/16/do-choles...   \n",
       "PLAIN-3  http://nutritionfacts.org/2015/07/14/breast-ca...   \n",
       "PLAIN-4  http://nutritionfacts.org/2015/07/09/using-die...   \n",
       "PLAIN-5  http://nutritionfacts.org/2015/07/07/treating-...   \n",
       "\n",
       "                                               TITLE  \\\n",
       "ID                                                     \n",
       "PLAIN-1                    [deep, fri, food, cancer]   \n",
       "PLAIN-2  [cholesterol, statin, drug, breast, cancer]   \n",
       "PLAIN-3     [breast, cancer, cell, fee, cholesterol]   \n",
       "PLAIN-4                [diet, treat, asthma, eczema]   \n",
       "PLAIN-5                 [treat, asthma, plant, pill]   \n",
       "\n",
       "                                                  MAINTEXT  \\\n",
       "ID                                                           \n",
       "PLAIN-1  [latest, studi, dietari, pattern, breast, canc...   \n",
       "PLAIN-2  [breast, cancer, cholesterol, potenti, mechan,...   \n",
       "PLAIN-3  [american, women, diagnos, breast, cancer, lif...   \n",
       "PLAIN-4  [previous, discuss, power, fruit, veget, preve...   \n",
       "PLAIN-5  [video, treat, asthma, fruit, veget, highlight...   \n",
       "\n",
       "                                                  COMMENTS  \\\n",
       "ID                                                           \n",
       "PLAIN-1  Even before the oil gets in the fryer, it’s be...   \n",
       "PLAIN-2  Off topic, but what does the science say about...   \n",
       "PLAIN-3  When I eat fresh stalks of celery my mouth goe...   \n",
       "PLAIN-4  I am confused about coconut fat. Is it the pro...   \n",
       "PLAIN-5  Maybe the asthma trick is in what not to eat. ...   \n",
       "\n",
       "                                               TOPICS_TAGS DESCRIPTION  \\\n",
       "ID                                                                       \n",
       "PLAIN-1  [acrylamide, beans, breast cancer, cabbage, ca...           -   \n",
       "PLAIN-2  [breast cancer, cancer, cancer survival, cardi...           -   \n",
       "PLAIN-3  [body fat, breast cancer, breast cancer surviv...           -   \n",
       "PLAIN-4  [asthma, blood pressure, caloric restriction, ...           -   \n",
       "PLAIN-5  [allergies, antioxidants, apples, asthma, bean...           -   \n",
       "\n",
       "        DOCTORS_NOTE ARTICLE_LINKS QUESTION_LINKS  \\\n",
       "ID                                                  \n",
       "PLAIN-1            -             -              -   \n",
       "PLAIN-2            -             -              -   \n",
       "PLAIN-3            -             -              -   \n",
       "PLAIN-4            -             -              -   \n",
       "PLAIN-5            -             -              -   \n",
       "\n",
       "                                               TOPIC_LINKS  \\\n",
       "ID                                                           \n",
       "PLAIN-1  http://nutritionfacts.org/topics/organic-foods...   \n",
       "PLAIN-2  http://nutritionfacts.org/topics/organic-foods...   \n",
       "PLAIN-3  http://nutritionfacts.org/topics/organic-foods...   \n",
       "PLAIN-4  http://nutritionfacts.org/topics/organic-foods...   \n",
       "PLAIN-5  http://nutritionfacts.org/topics/organic-foods...   \n",
       "\n",
       "                                               VIDEO_LINKS  \\\n",
       "ID                                                           \n",
       "PLAIN-1  http://nutritionfacts.org/video/meat-fumes-die...   \n",
       "PLAIN-2  http://nutritionfacts.org/video/statin-cholest...   \n",
       "PLAIN-3  http://nutritionfacts.org/video/flaxseeds-brea...   \n",
       "PLAIN-4  http://nutritionfacts.org/video/uprooting-the-...   \n",
       "PLAIN-5  http://nutritionfacts.org/video/alkylphenol-en...   \n",
       "\n",
       "                                          MEDARTICLE_LINKS  \n",
       "ID                                                          \n",
       "PLAIN-1  http://www.ncbi.nlm.nih.gov/pubmed/23092936,ht...  \n",
       "PLAIN-2  http://www.ncbi.nlm.nih.gov/pubmed/16565487,ht...  \n",
       "PLAIN-3  http://www.ncbi.nlm.nih.gov/pubmed/3081176,htt...  \n",
       "PLAIN-4  http://www.ncbi.nlm.nih.gov/pubmed/11840688,ht...  \n",
       "PLAIN-5  http://www.ncbi.nlm.nih.gov/pubmed/21623967,ht...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preview dataset\n",
    "clean_queries.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW8wGur-zc1T"
   },
   "source": [
    "## Save clean query dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "QwdsBfiEzc1T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.genfromtxt(\"../Data/nfcorpus/raw/train.queries.ids\", delimiter='\\n', encoding=\"utf8\", dtype=None)\n",
    "print(len(train_indices))\n",
    "indices = []\n",
    "for index, a in enumerate(train_indices):\n",
    "    try:\n",
    "        clean_queries.loc[a]\n",
    "    except:\n",
    "        indices.append(index)\n",
    "\n",
    "train_indices = np.delete(train_indices, indices)\n",
    "\n",
    "clean_queries_train = clean_queries.loc[train_indices]\n",
    "\n",
    "clean_queries_train.to_csv('../Data/clean/query.train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "val_indices = np.genfromtxt(\"../Data/nfcorpus/raw/dev.queries.ids\", delimiter='\\n', encoding=\"utf8\", dtype=None)\n",
    "print(len(val_indices))\n",
    "indices = []\n",
    "for index, a in enumerate(val_indices):\n",
    "    try:\n",
    "        clean_queries.loc[a]\n",
    "    except:\n",
    "        indices.append(index)\n",
    "\n",
    "val_indices = np.delete(val_indices, indices)\n",
    "\n",
    "clean_queries_val = clean_queries.loc[val_indices]\n",
    "\n",
    "clean_queries_val.to_csv('../Data/clean/query.dev.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "test_indices = np.genfromtxt(\"../Data/nfcorpus/raw/test.queries.ids\", delimiter='\\n', encoding=\"utf8\", dtype=None)\n",
    "print(len(test_indices))\n",
    "indices = []\n",
    "for index, a in enumerate(test_indices):\n",
    "    try:\n",
    "        clean_queries.loc[a]\n",
    "    except:\n",
    "        indices.append(index)\n",
    "\n",
    "test_indices = np.delete(test_indices, indices)\n",
    "\n",
    "clean_queries_test = clean_queries.loc[test_indices]\n",
    "\n",
    "clean_queries_test.to_csv('../Data/clean/query.test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X3NXR7izc1U"
   },
   "source": [
    "## Load the document dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "executionInfo": {
     "elapsed": 23989,
     "status": "ok",
     "timestamp": 1608213634209,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "wQVKBz4Azc1U",
    "outputId": "d45cf38b-e54a-4327-cbf3-3f577c72a477"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MED-1</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/23092936</td>\n",
       "      <td>[birth, weight, head, circumfer, prenat, expos...</td>\n",
       "      <td>[background, acrylamid, common, dietari, expos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-2</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/22809476</td>\n",
       "      <td>[statist, regress, model, estim, acrylamid, co...</td>\n",
       "      <td>[human, exposur, acrylamid, consumpt, french, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-3</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/19158207</td>\n",
       "      <td>[chronic, intak, potato, chip, human, increas,...</td>\n",
       "      <td>[background, high, concentr, acrylamid, common...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-4</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/23651876</td>\n",
       "      <td>[dietari, pattern, breast, cancer, risk, women...</td>\n",
       "      <td>[object, breast, cancer, common, type, cancer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-5</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/16332665</td>\n",
       "      <td>[empir, deriv, dietari, pattern, risk, postmen...</td>\n",
       "      <td>[background, inconsist, associ, report, diet, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               URL  \\\n",
       "ID                                                   \n",
       "MED-1  http://www.ncbi.nlm.nih.gov/pubmed/23092936   \n",
       "MED-2  http://www.ncbi.nlm.nih.gov/pubmed/22809476   \n",
       "MED-3  http://www.ncbi.nlm.nih.gov/pubmed/19158207   \n",
       "MED-4  http://www.ncbi.nlm.nih.gov/pubmed/23651876   \n",
       "MED-5  http://www.ncbi.nlm.nih.gov/pubmed/16332665   \n",
       "\n",
       "                                                   TITLE  \\\n",
       "ID                                                         \n",
       "MED-1  [birth, weight, head, circumfer, prenat, expos...   \n",
       "MED-2  [statist, regress, model, estim, acrylamid, co...   \n",
       "MED-3  [chronic, intak, potato, chip, human, increas,...   \n",
       "MED-4  [dietari, pattern, breast, cancer, risk, women...   \n",
       "MED-5  [empir, deriv, dietari, pattern, risk, postmen...   \n",
       "\n",
       "                                                ABSTRACT  \n",
       "ID                                                        \n",
       "MED-1  [background, acrylamid, common, dietari, expos...  \n",
       "MED-2  [human, exposur, acrylamid, consumpt, french, ...  \n",
       "MED-3  [background, high, concentr, acrylamid, common...  \n",
       "MED-4  [object, breast, cancer, common, type, cancer,...  \n",
       "MED-5  [background, inconsist, associ, report, diet, ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs_dataset = pd.read_csv(\"../Data/nfcorpus/raw/doc_dump.txt\", sep='\\t', index_col=False, header=None )\n",
    "column_names = { \n",
    "    0: \"ID\",\n",
    "    1 : \"URL\", \n",
    "    2 : \"TITLE\",\n",
    "    3 : \"ABSTRACT\"\n",
    "}\n",
    "raw_docs_dataset = raw_docs_dataset.rename(columns=column_names)\n",
    "\n",
    "raw_docs_dataset = raw_docs_dataset.set_index('ID')\n",
    "\n",
    "docs_dataset = raw_docs_dataset.copy()\n",
    "## Stopword removal, Lemmatize and stemming of the title and abstract\n",
    "docs_dataset.TITLE = docs_dataset.TITLE.apply(preprocess)\n",
    "docs_dataset.ABSTRACT = docs_dataset.ABSTRACT.apply(preprocess)\n",
    "\n",
    "\n",
    "\n",
    "#docs_dataset.TITLE = np.expand_dims(np.squeeze([doc.split(\" \") for doc in docs_dataset.TITLE.values]), axis=1)\n",
    "#docs_dataset.ABSTRACT = ([doc.split(\" \") for doc in docs_dataset.ABSTRACT.values])\n",
    "# Remove standard title beginning from abstract (\"Abstract:\", \"Abstract Background:\", \"Background research\" and \"Abstract Background and methods\"\n",
    "#Remove Abstract as first word from the paper\n",
    "docs_dataset.ABSTRACT = [doc[1:] if \"abstract\" in doc[0].lower() else doc for doc in docs_dataset.ABSTRACT.values]\n",
    "# Remove background if it is the first or second word of the paper\n",
    "#docs_dataset.ABSTRACT = [doc[1:] if \"background\" in doc[0].lower() else doc for doc in docs_dataset.ABSTRACT.values]\n",
    "#Remove the first words if an : occured in \n",
    "docs_dataset.ABSTRACT = [doc[1 + min([i for i,x in enumerate(doc) if ':' in x]):] if min([i for i,x in enumerate(doc) if ':' in x], default = 999) < 5  else doc for doc in docs_dataset.ABSTRACT.values]\n",
    "\n",
    "docs_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1608213688183,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "fkcpDEngzc1U",
    "outputId": "1ffdb0cf-8e82-4aab-df8e-2e7f1dbc5d24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\t Abstract Recent studies have suggested that statins, an established drug group in the prevention of cardiovascular mortality, could delay or prevent breast cancer recurrence but the effect on disease-specific mortality remains unclear. We evaluated risk of breast cancer death among statin users in a population-based cohort of breast cancer patients. The study cohort included all newly diagnosed breast cancer patients in Finland during 1995–2003 (31,236 cases), identified from the Finnish Cancer Registry. Information on statin use before and after the diagnosis was obtained from a national prescription database. We used the Cox proportional hazards regression method to estimate mortality among statin users with statin use as time-dependent variable. A total of 4,151 participants had used statins. During the median follow-up of 3.25 years after the diagnosis (range 0.08–9.0 years) 6,011 participants died, of which 3,619 (60.2%) was due to breast cancer. Aft\n",
      "Preprocessed\t ['recent', 'studi', 'suggest', 'statin', 'establish', 'drug', 'group', 'prevent', 'cardiovascular', 'mortal', 'delay', 'prevent', 'breast', 'cancer', 'recurr', 'effect', 'diseas', 'specif', 'mortal', 'remain', 'unclear', 'evalu', 'risk', 'breast', 'cancer', 'death', 'statin', 'user', 'popul', 'base', 'cohort', 'breast', 'cancer', 'patient', 'studi', 'cohort', 'includ', 'newli', 'diagnos', 'breast', 'cancer', 'patient', 'finland', 'case', 'identifi', 'finnish', 'cancer', 'registri', 'inform', 'statin', 'diagnosi', 'obtain', 'nation', 'prescript', 'databas', 'proport', 'hazard', 'regress', 'method', 'estim', 'mortal', 'statin', 'user', 'statin', 'time', 'depend', 'variabl', 'total', 'particip', 'statin', 'median', 'follow', 'year', 'diagnosi', 'rang', 'year', 'particip', 'die', 'breast', 'cancer', 'adjust', 'tumor', 'characterist', 'treatment', 'select', 'post', 'diagnost', 'diagnost', 'statin', 'lower', 'risk', 'breast', 'cancer', 'death', 'risk', 'decreas', 'post', 'diagnost', 'statin', 'affect', 'healthi', 'adher', 'bias', 'greater', 'likelihood', 'die', 'cancer', 'patient', 'discontinu', 'statin', 'associ', 'dose', 'depend', 'observ', 'dose', 'short', 'term', 'dose', 'time', 'depend', 'surviv', 'benefit', 'diagnost', 'statin', 'user', 'suggest', 'causal', 'effect', 'evalu', 'clinic', 'trial', 'test', 'statin', 'effect', 'surviv', 'breast', 'cancer', 'patient']\n"
     ]
    }
   ],
   "source": [
    "#Example result:\n",
    "preprocessed_abstract = docs_dataset.ABSTRACT.loc['MED-10'][:]\n",
    "\n",
    "print(\"Original:\\t\", raw_docs_dataset.ABSTRACT.loc['MED-10'][:len(' '.join(preprocessed_abstract))])\n",
    "print(\"Preprocessed\\t\", preprocessed_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXKMdqJnzc1V"
   },
   "source": [
    "## Create document train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write one full clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be deleted: 283\n"
     ]
    }
   ],
   "source": [
    "#Remove all documents without topic\n",
    "med_indices_filepath = \"../Data/clean/med_documents.csv\"\n",
    "med_indices = pd.read_csv(med_indices_filepath,encoding=\"utf8\",header=1, index_col=0)\n",
    "indices = []\n",
    "for index, a in enumerate(med_indices.itertuples()):\n",
    "    if(len(a[1])< 3):\n",
    "        indices.append(index)\n",
    "\n",
    "#print(med_indices)\n",
    "print(\"To be deleted:\", len(indices))\n",
    "med_indices = np.delete(med_indices.index.values, indices)\n",
    "\n",
    "docs_dataset = docs_dataset.loc[med_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1608213895869,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "E4biptifzc1V",
    "outputId": "e9d02d1f-db84-4a67-a1ae-ff6444eb8323"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MED-2</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/22809476</td>\n",
       "      <td>[statist, regress, model, estim, acrylamid, co...</td>\n",
       "      <td>[human, exposur, acrylamid, consumpt, french, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-3</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/19158207</td>\n",
       "      <td>[chronic, intak, potato, chip, human, increas,...</td>\n",
       "      <td>[background, high, concentr, acrylamid, common...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-4</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/23651876</td>\n",
       "      <td>[dietari, pattern, breast, cancer, risk, women...</td>\n",
       "      <td>[object, breast, cancer, common, type, cancer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-5</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/16332665</td>\n",
       "      <td>[empir, deriv, dietari, pattern, risk, postmen...</td>\n",
       "      <td>[background, inconsist, associ, report, diet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MED-6</th>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/23335051</td>\n",
       "      <td>[consumpt, deep, fri, food, risk, prostat, can...</td>\n",
       "      <td>[background, evid, suggest, high, heat, cook, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               URL  \\\n",
       "ID                                                   \n",
       "MED-2  http://www.ncbi.nlm.nih.gov/pubmed/22809476   \n",
       "MED-3  http://www.ncbi.nlm.nih.gov/pubmed/19158207   \n",
       "MED-4  http://www.ncbi.nlm.nih.gov/pubmed/23651876   \n",
       "MED-5  http://www.ncbi.nlm.nih.gov/pubmed/16332665   \n",
       "MED-6  http://www.ncbi.nlm.nih.gov/pubmed/23335051   \n",
       "\n",
       "                                                   TITLE  \\\n",
       "ID                                                         \n",
       "MED-2  [statist, regress, model, estim, acrylamid, co...   \n",
       "MED-3  [chronic, intak, potato, chip, human, increas,...   \n",
       "MED-4  [dietari, pattern, breast, cancer, risk, women...   \n",
       "MED-5  [empir, deriv, dietari, pattern, risk, postmen...   \n",
       "MED-6  [consumpt, deep, fri, food, risk, prostat, can...   \n",
       "\n",
       "                                                ABSTRACT  \n",
       "ID                                                        \n",
       "MED-2  [human, exposur, acrylamid, consumpt, french, ...  \n",
       "MED-3  [background, high, concentr, acrylamid, common...  \n",
       "MED-4  [object, breast, cancer, common, type, cancer,...  \n",
       "MED-5  [background, inconsist, associ, report, diet, ...  \n",
       "MED-6  [background, evid, suggest, high, heat, cook, ...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_dataset.to_csv('../Data/clean/doc.all.csv')\n",
    "\n",
    "# forget the raw dataset\n",
    "raw_docs_dataset =  None\n",
    "\n",
    "docs_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the training document dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices_filepath = \"../Data/nfcorpus/raw/train.docs.ids\"\n",
    "train_indices = np.genfromtxt(train_indices_filepath, delimiter='\\n', encoding=\"utf8\", dtype=None)\n",
    "docs_dataset_train = docs_dataset.loc[train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices_filepath = \"../Data/nfcorpus/raw/dev.docs.ids\"\n",
    "val_indices = np.genfromtxt(val_indices_filepath, delimiter='\\n', encoding=\"utf8\", dtype=None)\n",
    "indices = []\n",
    "for index, a in enumerate(val_indices):\n",
    "    try:\n",
    "        docs_dataset.loc[a]\n",
    "    except:\n",
    "        indices.append(index)\n",
    "\n",
    "val_indices = np.delete(val_indices, indices)\n",
    "\n",
    "docs_dataset_val = docs_dataset.loc[val_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices_filepath = \"../Data/nfcorpus/raw/test.docs.ids\"\n",
    "test_indices = np.genfromtxt(test_indices_filepath, delimiter='\\n', encoding=\"utf8\", dtype=None)\n",
    "indices = []\n",
    "for index, a in enumerate(test_indices):\n",
    "    try:\n",
    "        docs_dataset.loc[a]\n",
    "    except:\n",
    "        indices.append(index)\n",
    "\n",
    "test_indices = np.delete(test_indices, indices)\n",
    "docs_dataset_test = docs_dataset.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1608213905316,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "qq6Wq6jUzc1V",
    "outputId": "c9342318-552a-49bc-efac-cbfaf1ed420c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL         object\n",
       "TITLE       object\n",
       "ABSTRACT    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_dataset_train.to_csv('../Data/clean/doc.train.csv')\n",
    "docs_dataset_val.to_csv('../Data/clean/doc.dev.csv')\n",
    "docs_dataset_test.to_csv('../Data/clean/doc.test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWK_mu2czc1Y"
   },
   "source": [
    "## Create bm25 ranking for all documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process train queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3419/3419 [08:58<00:00,  6.35it/s]\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25Okapi((docs_dataset['TITLE'] + docs_dataset['ABSTRACT']))\n",
    "\n",
    "bm25_ranking = pd.DataFrame(columns = ['query','ranking', 'scores'])\n",
    "row_index = 0\n",
    "for row in tqdm(clean_queries.itertuples(), total=len(clean_queries)):\n",
    "    tokenized_query = row.TITLE + row.MAINTEXT \n",
    "\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    # Get the first 1000 indexes of the sorted list\n",
    "    # Make array negative to achieve sorting in descending order\n",
    "    ranking = np.argsort(-doc_scores, axis=0)[:1000]\n",
    "    top_1000_rank   = docs_dataset.iloc[ranking].index.values\n",
    "    top_1000_scores = doc_scores[ranking]\n",
    "\n",
    "    bm25_ranking.loc[row_index] = [row.Index, top_1000_rank.tolist(), top_1000_scores.tolist()]\n",
    "    row_index += 1\n",
    "\n",
    "bm25_ranking = bm25_ranking.set_index('query')\n",
    "# bm25_ranking.to_csv('../Data/clean/ranking.bm25.train2.csv', sep=',')\n",
    "bm25_ranking.to_csv('../Data/results/ranking.bm25.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_ranking.to_csv('../Data/results/ranking.bm25.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394371,
     "status": "ok",
     "timestamp": 1608221825059,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "c-5_E9rKzc1Y",
    "outputId": "d5f69a65-d14b-44a9-b749-624ba330466c"
   },
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi((docs_dataset['TITLE'] + docs_dataset['ABSTRACT']))\n",
    "\n",
    "bm25_ranking = pd.DataFrame(columns = ['query','ranking', 'scores'])\n",
    "row_index = 0\n",
    "for row in tqdm(clean_queries_train.itertuples(), total=len(clean_queries_train)):\n",
    "    tokenized_query = row.MAINTEXT\n",
    "\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    # Get the first 1000 indexes of the sorted list\n",
    "    # Make array negative to achieve sorting in descending order\n",
    "    ranking = np.argsort(-doc_scores, axis=0)[:1000]\n",
    "    top_1000_rank   = docs_dataset.iloc[ranking].index.values\n",
    "    top_1000_scores = doc_scores[ranking]\n",
    "\n",
    "    bm25_ranking.loc[row_index] = [row.Index, top_1000_rank.tolist(), top_1000_scores.tolist()]\n",
    "    row_index += 1\n",
    "\n",
    "bm25_ranking = bm25_ranking.set_index('query')\n",
    "# bm25_ranking.to_csv('../Data/clean/ranking.bm25.train2.csv', sep=',')\n",
    "bm25_ranking.to_csv('../Data/results/ranking.bm25.train.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process validation queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi((docs_dataset['TITLE'] + docs_dataset['ABSTRACT']))\n",
    "\n",
    "bm25_ranking = pd.DataFrame(columns = ['query','ranking', 'scores'])\n",
    "row_index = 0\n",
    "for row in tqdm(clean_queries_val.itertuples(), total=len(clean_queries_val)):\n",
    "    tokenized_query = row.MAINTEXT\n",
    "\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    # get the first 1000 indexes of the sorted list\n",
    "    # Make array negative to achieve sorting in descending order\n",
    "    ranking = np.argsort(-doc_scores, axis=0)[:1000]\n",
    "    top_1000_rank   = docs_dataset.iloc[ranking].index.values\n",
    "    top_1000_scores = doc_scores[ranking]\n",
    "\n",
    "    bm25_ranking.loc[row_index] = [row.Index, top_1000_rank.tolist(), top_1000_scores.tolist()]\n",
    "    row_index += 1\n",
    "\n",
    "bm25_ranking = bm25_ranking.set_index('query')\n",
    "# bm25_ranking.to_csv('../Data/clean/ranking.bm25.train2.csv', sep=',')\n",
    "bm25_ranking.to_csv('../Data/results/ranking.bm25.dev.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi((docs_dataset['TITLE'] + docs_dataset['ABSTRACT']))\n",
    "\n",
    "bm25_ranking = pd.DataFrame(columns = ['query','ranking', 'scores'])\n",
    "row_index = 0\n",
    "for row in tqdm(clean_queries_test.itertuples(), total=len(clean_queries_test)):\n",
    "    tokenized_query = row.MAINTEXT\n",
    "\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    # get the first 1000 indexes of the sorted list\n",
    "    # Make array negative to achieve sorting in descending order\n",
    "    ranking = np.argsort(-doc_scores, axis=0)[:1000]\n",
    "    top_1000_rank   = docs_dataset.iloc[ranking].index.values\n",
    "    top_1000_scores = doc_scores[ranking]\n",
    "\n",
    "    bm25_ranking.loc[row_index] = [row.Index, top_1000_rank.tolist(), top_1000_scores.tolist()]\n",
    "    row_index += 1\n",
    "\n",
    "bm25_ranking = bm25_ranking.set_index('query')\n",
    "# bm25_ranking.to_csv('../Data/clean/ranking.bm25.train2.csv', sep=',')\n",
    "bm25_ranking.to_csv('../Data/results/ranking.bm25.test.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1608222147472,
     "user": {
      "displayName": "Marit Hagens",
      "photoUrl": "",
      "userId": "00896192743889461878"
     },
     "user_tz": -60
    },
    "id": "cA8APk_Bzc1Y",
    "outputId": "f7e9dde4-b5ff-4d52-b349-4eb985582107"
   },
   "outputs": [],
   "source": [
    "bm25_ranking"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Create ranking datasets BM25.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
